{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names, get_dataset_config_info, interleave_datasets\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-1**\n",
    "link to dataset: https://huggingface.co/datasets/ai4bharat/naamapadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_dataset_config_names('ai4bharat/naamapadam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SplitInfo(name='train',\n",
      "          num_bytes=529397194,\n",
      "          num_examples=985787,\n",
      "          shard_lengths=[931000, 54787],\n",
      "          dataset_name='naamapadam')\n"
     ]
    }
   ],
   "source": [
    "pprint(get_dataset_config_info('ai4bharat/naamapadam', 'hi').splits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetInfo(description='\\n',\n",
      "            citation='\\n',\n",
      "            homepage='https://indicnlp.ai4bharat.org/',\n",
      "            license='Creative Commons Attribution-NonCommercial 4.0 '\n",
      "                    'International Public License',\n",
      "            features={'ner_tags': Sequence(feature=ClassLabel(names=['O',\n",
      "                                                                     'B-PER',\n",
      "                                                                     'I-PER',\n",
      "                                                                     'B-ORG',\n",
      "                                                                     'I-ORG',\n",
      "                                                                     'B-LOC',\n",
      "                                                                     'I-LOC'],\n",
      "                                                              id=None),\n",
      "                                           length=-1,\n",
      "                                           id=None),\n",
      "                      'tokens': Sequence(feature=Value(dtype='string', id=None),\n",
      "                                         length=-1,\n",
      "                                         id=None)},\n",
      "            post_processed=None,\n",
      "            supervised_keys=None,\n",
      "            builder_name='parquet',\n",
      "            dataset_name='naamapadam',\n",
      "            config_name='ta',\n",
      "            version='1.0.0',\n",
      "            splits={'test': SplitInfo(name='test',\n",
      "                                      num_bytes=319747,\n",
      "                                      num_examples=758,\n",
      "                                      shard_lengths=None,\n",
      "                                      dataset_name='naamapadam'),\n",
      "                    'train': SplitInfo(name='train',\n",
      "                                       num_bytes=186464659,\n",
      "                                       num_examples=497882,\n",
      "                                       shard_lengths=None,\n",
      "                                       dataset_name='naamapadam'),\n",
      "                    'validation': SplitInfo(name='validation',\n",
      "                                            num_bytes=1046343,\n",
      "                                            num_examples=2795,\n",
      "                                            shard_lengths=None,\n",
      "                                            dataset_name='naamapadam')},\n",
      "            download_checksums={'https://huggingface.co/datasets/ai4bharat/naamapadam/resolve/main/data/ta_IndicNER_v1.0.zip': {'checksum': None,\n",
      "                                                                                                                                'num_bytes': 29707348}},\n",
      "            download_size=29707348,\n",
      "            post_processing_size=None,\n",
      "            dataset_size=187830749,\n",
      "            size_in_bytes=217538097)\n"
     ]
    }
   ],
   "source": [
    "pprint(get_dataset_config_info('ai4bharat/naamapadam', 'ta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner_tags': Sequence(feature=ClassLabel(names=['O',\n",
      "                                                'B-PER',\n",
      "                                                'I-PER',\n",
      "                                                'B-ORG',\n",
      "                                                'I-ORG',\n",
      "                                                'B-LOC',\n",
      "                                                'I-LOC'],\n",
      "                                         id=None),\n",
      "                      length=-1,\n",
      "                      id=None),\n",
      " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "pprint(get_dataset_config_info('ai4bharat/naamapadam', 'hi').features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('ai4bharat/naamapadam', 'ta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [{'filename': 'C:\\\\Users\\\\gagan\\\\.cache\\\\huggingface\\\\datasets\\\\ai4bharat___naamapadam\\\\ta\\\\1.0.0\\\\9d4f21ac57d11ed4f9ea64854fdc9f5618e61acc\\\\naamapadam-train.arrow'}],\n",
       " 'test': [{'filename': 'C:\\\\Users\\\\gagan\\\\.cache\\\\huggingface\\\\datasets\\\\ai4bharat___naamapadam\\\\ta\\\\1.0.0\\\\9d4f21ac57d11ed4f9ea64854fdc9f5618e61acc\\\\naamapadam-test.arrow'}],\n",
       " 'validation': [{'filename': 'C:\\\\Users\\\\gagan\\\\.cache\\\\huggingface\\\\datasets\\\\ai4bharat___naamapadam\\\\ta\\\\1.0.0\\\\9d4f21ac57d11ed4f9ea64854fdc9f5618e61acc\\\\naamapadam-validation.arrow'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.cache_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size in MB: 226.22\n"
     ]
    }
   ],
   "source": [
    "bytes_size_ds = get_dataset_config_info('ai4bharat/naamapadam', 'ta').size_in_bytes\n",
    "size_in_mb = bytes_size_ds / (1024 * 1024)\n",
    "\n",
    "print(f\"Size in MB: {size_in_mb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497882"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataset_config_info(path='ai4bharat/naamapadam', config_name='ta').splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 497882\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 758\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 2795\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "pprint(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8365adef2224b2a9dfa24cbd1f9a52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/497882 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d183793349c46aeb74a76799a7da34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/758 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ba68d3fc6547548104604c8c5888b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2795 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'num_tokens'],\n",
      "        num_rows: 497882\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'num_tokens'],\n",
      "        num_rows: 758\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'num_tokens'],\n",
      "        num_rows: 2795\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(x):\n",
    "    x['num_tokens'] = len(x['tokens'])\n",
    "    return x\n",
    "\n",
    "ds_mapped = ds.map(count_tokens)\n",
    "pprint(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in train: 5959032\n",
      "Total tokens in test: 9528\n",
      "Total tokens in validation: 33316\n",
      "Total tokens (in millions): 6.0 million\n"
     ]
    }
   ],
   "source": [
    "train_tok = ds_mapped['train']['num_tokens']\n",
    "test_tok = ds_mapped['test']['num_tokens']\n",
    "validation_tok = ds_mapped['validation']['num_tokens']\n",
    "\n",
    "train_tokens = 0\n",
    "for i in train_tok:\n",
    "    train_tokens += i\n",
    "\n",
    "test_tokens = 0\n",
    "for i in test_tok:\n",
    "    test_tokens += i\n",
    "\n",
    "validation_tokens = 0\n",
    "for i in validation_tok:\n",
    "    validation_tokens += i\n",
    "\n",
    "print(f\"Total tokens in train: {train_tokens}\")\n",
    "print(f\"Total tokens in test: {test_tokens}\")\n",
    "print(f\"Total tokens in validation: {validation_tokens}\")\n",
    "\n",
    "print(f\"Total tokens (in millions): {round((train_tokens + test_tokens + validation_tokens)/1000000, 0)} million\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_merge = load_dataset('ai4bharat/naamapadam', 'ta', split='train+test+validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fab5fd3d3374d1c9b57e9ed7aa341ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/501435 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the 'text' column\n",
    "def create_text(example):\n",
    "    example['text'] = ' '.join(example['tokens'])\n",
    "    return example\n",
    "\n",
    "ds = ds_merge.map(create_text)\n",
    "\n",
    "# Remove the 'ner_tags' and 'tokens' columns\n",
    "ds = ds.remove_columns(['ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 501435\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "pprint(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395ba92bda7141cfbbfad9aca5ab31ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/501435 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 370495\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "num_words = 6\n",
    "ds_filtered = ds.filter(lambda x:len(x['text'].split(' '))>=num_words)\n",
    "print(ds_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8588c924c244a583069b9eff4b32a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/49.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gagan\\OneDrive\\Desktop\\DLP\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\gagan\\.cache\\huggingface\\hub\\datasets--ai4bharat--indic_glue. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540179657e0c4a94a8eb17ace4046303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.02M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdfc11d90bd4820be757d857ac5a924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/124k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c023e1192c36482c84f052a4e4361a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/126k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1034eeaf47fe4df6b38ebaa6d35b2e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e7ce28ae594d15b698f5d185d72358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/669 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3b3f675d0c48e08daac1c62679a873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/669 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indic_glue_tamil = load_dataset('ai4bharat/indic_glue', 'inltkh.ta', split='train+test+validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'கே.வி.ஆனந்தே ட்விட்டரில் இதை அறிவித்துள்ளார். இந்தப் படத்துக்கு கேவ்மிக் ஆரி ஒளிப்பதிவு செய்ய, ஹாரிஸ் ஜெயராஜ் இசையமைக்கிறார். பட்டுக்கோட்டை பிரபாகர் வசனம் எழுத, கலை இயக்குநராக கிரண் பணியாற்றுகிறார். இந்தப் படத்தை லைகா புரொடக்\\u200cஷன்ஸ் நிறுவனம் தயாரிக்கிறது.',\n",
       " 'label': 6}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indic_glue_tamil[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c0f1873aa644d885d6ae2f317dbd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 6428\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "num_words = 6\n",
    "indic_glue_tamil_filtered = indic_glue_tamil.filter(lambda x:len(x['text'].split(' '))>=num_words)\n",
    "print(indic_glue_tamil_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 32354\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "inter_ds = interleave_datasets([ds_filtered, indic_glue_tamil_filtered], probabilities=[0.8, 0.2], seed=42)\n",
    "print(inter_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
