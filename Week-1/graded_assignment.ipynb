{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names, get_dataset_config_info, interleave_datasets\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-1**\n",
    "link to dataset: https://huggingface.co/datasets/ai4bharat/naamapadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(get_dataset_config_names('ai4bharat/naamapadam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(get_dataset_config_info('ai4bharat/naamapadam', 'hi').splits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(get_dataset_config_info('ai4bharat/naamapadam', 'ta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(get_dataset_config_info('ai4bharat/naamapadam', 'hi').features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('ai4bharat/naamapadam', 'ta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.cache_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_size_ds = get_dataset_config_info('ai4bharat/naamapadam', 'ta').size_in_bytes\n",
    "size_in_mb = bytes_size_ds / (1024 * 1024)\n",
    "\n",
    "print(f\"Size in MB: {size_in_mb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_config_info(path='ai4bharat/naamapadam', config_name='ta').splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(x):\n",
    "    x['num_tokens'] = len(x['tokens'])\n",
    "    return x\n",
    "\n",
    "ds_mapped = ds.map(count_tokens)\n",
    "pprint(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = ds_mapped['train']['num_tokens']\n",
    "test_tok = ds_mapped['test']['num_tokens']\n",
    "validation_tok = ds_mapped['validation']['num_tokens']\n",
    "\n",
    "train_tokens = 0\n",
    "for i in train_tok:\n",
    "    train_tokens += i\n",
    "\n",
    "test_tokens = 0\n",
    "for i in test_tok:\n",
    "    test_tokens += i\n",
    "\n",
    "validation_tokens = 0\n",
    "for i in validation_tok:\n",
    "    validation_tokens += i\n",
    "\n",
    "print(f\"Total tokens in train: {train_tokens}\")\n",
    "print(f\"Total tokens in test: {test_tokens}\")\n",
    "print(f\"Total tokens in validation: {validation_tokens}\")\n",
    "\n",
    "print(f\"Total tokens (in millions): {round((train_tokens + test_tokens + validation_tokens)/1000000, 0)} million\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_merge = load_dataset('ai4bharat/naamapadam', 'ta', split='train+test+validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'text' column\n",
    "def create_text(example):\n",
    "    example['text'] = ' '.join(example['tokens'])\n",
    "    return example\n",
    "\n",
    "ds = ds_merge.map(create_text)\n",
    "\n",
    "# Remove the 'ner_tags' and 'tokens' columns\n",
    "ds = ds.remove_columns(['ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 6\n",
    "ds_filtered = ds.filter(lambda x:len(x['text'].split(' '))>=num_words)\n",
    "print(ds_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indic_glue_tamil = load_dataset('ai4bharat/indic_glue', 'inltkh.ta', split='train+test+validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indic_glue_tamil[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 6\n",
    "indic_glue_tamil_filtered = indic_glue_tamil.filter(lambda x:len(x['text'].split(' '))>=num_words)\n",
    "print(indic_glue_tamil_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_ds = interleave_datasets([ds_filtered, indic_glue_tamil_filtered], probabilities=[0.8, 0.2], seed=42)\n",
    "print(inter_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
